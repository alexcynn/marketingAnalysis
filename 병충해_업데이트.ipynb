{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdQ3cRS8OVPFT6RkaJcWuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcynn/marketingAnalysis/blob/master/%EB%B3%91%EC%B6%A9%ED%95%B4_%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3sEsPEEsku5",
        "outputId": "c9f2d47e-9e90-417a-c94f-98f6993f1eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warning List:\n",
            "['(과수-배)과수화상병', '(과수-사과)가지검은마름병', '(과수-사과)과수화상병']\n",
            "watch List:\n",
            "['(과수-배)미국선녀벌레', '(과수-배)복숭아심식나방', '(과수-복숭아)복숭아순나방', '(과수-복숭아)복숭아심식나방', '(과수-사과)갈색날개매미충', '(과수-사과)갈색무늬병', '(과수-사과)복숭아순나방', '(과수-사과)복숭아심식나방', '(과수-사과)탄저병', '(과수-포도)꽃매미', '(과수-포도)미국선녀벌레', '(채소-고추)담배나방', '(채소-고추)역병', '(채소-고추)탄저병', '(채소-토마토)반점위조바이러스']\n",
            "forecast List:\n",
            "['(식량작물-논벼)벼멸구', '(식량작물-논벼)잎도열병', '(식량작물-논벼)잎집무늬마름병', '(식량작물-논벼)혹명나방', '(식량작물-논벼)흰등멸구', '(식량작물-논벼)흰잎마름병', '(식량작물-옥수수)멸강나방', '(식량작물-옥수수)열대거세미나방', '(과수-배)점박이응애', '(과수-사과)갈색날개노린재', '(과수-사과)썩덩나무노린재', '(과수-사과)점박이응애', '(채소-고추)꽃노랑총채벌레', '(채소-고추)목화진딧물', '(채소-딸기)온실가루이', '(채소-무)무름병', '(채소-무)뿌리혹병, 무사마귀병', '(채소-배추)무름병', '(채소-배추)뿌리혹병, 무사마귀병', '(채소-오이)꽃노랑총채벌레', '(채소-오이)담배가루이', '(채소-오이)목화진딧물', '(채소-오이)온실가루이', '(채소-토마토)담배가루이', '(채소-토마토)목화진딧물', '(채소-토마토)온실가루이']\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://ncpms.rda.go.kr/npms/NewIndcUserR.np?indcMon=&indcSeq=182\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# BeautifulSoup를 사용하여 HTML 파싱\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# 원하는 요소를 선택합니다.\n",
        "class1 = ['warning', 'watch', 'forecast']\n",
        "\n",
        "# 클래스별로 크롤링한 값을 저장할 딕셔너리\n",
        "alert_data = {key: [] for key in class1}\n",
        "\n",
        "# 선택한 요소에서 데이터 추출\n",
        "for class_name in class1:\n",
        "    alerts = soup.find_all('li', class_=class_name)  # <li> 태그 안의 해당 클래스명을 가진 요소를 선택\n",
        "\n",
        "    for alert in alerts:\n",
        "        alert_text = alert.get_text().strip()\n",
        "        alert_text = alert_text.split('\\n')\n",
        "        alert_text = [item for item in alert_text if item.strip()]  # 태그 내의 텍스트를 추출하고 양쪽 공백을 제거\n",
        "        alert_data[class_name].append(alert_text[1:])  # 결과를 딕셔너리에 추가, 첫 번째 값을 제외하고 추가\n",
        "\n",
        "# 결과 출력\n",
        "for class_name, data in alert_data.items():\n",
        "    print(f\"{class_name} List:\")\n",
        "    for item in data:\n",
        "        print(item)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 웹 페이지 요청\n",
        "url = 'https://ncpms.rda.go.kr/npms/NewIndcUserListR.np'\n",
        "res = requests.get(url)\n",
        "\n",
        "# BeautifulSoup를 사용하여 HTML 파싱\n",
        "soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "# 온클릭 값을 추출할 요소 선택\n",
        "a_1 = soup.select('table > tbody > tr:nth-child(1) > td:nth-child(2) > a')\n",
        "\n",
        "# 온클릭 속성 값을 가져와서 출력\n",
        "if a_1:\n",
        "    onclick_value = a_1[0].get('onclick')\n",
        "    numbers = re.sub(r'[^0-9]', '', onclick_value) #숫자만 추출\n",
        "    adress = 'https://ncpms.rda.go.kr/npms/NewIndcUserR.np?indcMon=&indcSeq='+ numbers\n",
        "    print(adress)\n",
        "else:\n",
        "    print(\"해당 요소를 찾을 수 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MLgU5DCsl-a",
        "outputId": "3a055f73-370d-409c-aade-b1d64a551888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ncpms.rda.go.kr/npms/NewIndcUserR.np?indcMon=&indcSeq=218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-CuEvF_6c2S",
        "outputId": "b52bfcaa-2fd5-4bdd-dad5-842eef1c8578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.2.0-cp310-cp310-manylinux_2_17_x86_64.whl (31.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.6/31.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=4.21.12,>=4.21.1 (from mysql-connector-python)\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, mysql-connector-python\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.21.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mysql-connector-python-8.2.0 protobuf-4.21.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import mysql.connector\n",
        "from datetime import datetime\n",
        "\n",
        "# Connect to your MySQL database\n",
        "mydb = mysql.connector.connect(\n",
        "    host=\"biz-transfarmer-db-new.ch4ybkmideyg.ap-northeast-2.rds.amazonaws.com\",\n",
        "    user=\"transfarmer\",\n",
        "    password=\"/transfarmer4321\",\n",
        "    database=\"transfarmer\"\n",
        ")\n",
        "\n",
        "# Create a cursor to interact with the database\n",
        "mycursor = mydb.cursor()\n",
        "\n",
        "# Regular expression pattern to extract dates in the format YYYY.MM.DD\n",
        "date_pattern = r'\\d{4}\\.\\d{1,2}\\.\\d{1,2}'\n",
        "\n",
        "# 웹 페이지 요청\n",
        "url = 'https://ncpms.rda.go.kr/npms/NewIndcUserListR.np'\n",
        "res = requests.get(url)\n",
        "\n",
        "# BeautifulSoup를 사용하여 HTML 파싱\n",
        "soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "# 온클릭 값을 추출할 요소 선택\n",
        "a_1 = soup.select('table > tbody > tr:nth-child(1) > td:nth-child(2) > a')\n",
        "\n",
        "\n",
        "def convertDate(date_str) :\n",
        "  # Convert the string to a datetime object\n",
        "  date_obj = datetime.strptime(date_str, \"%Y.%m.%d\")\n",
        "\n",
        "  # Format the datetime object as YYYYMMDD\n",
        "  formatted_date = date_obj.strftime(\"%Y%m%d\")\n",
        "  return formatted_date\n",
        "\n",
        "# 온클릭 속성 값을 가져와서 출력\n",
        "if a_1:\n",
        "    onclick_value = a_1[0].get('onclick')\n",
        "    numbers = re.sub(r'[^0-9]', '', onclick_value) #숫자만 추출\n",
        "    url = 'https://ncpms.rda.go.kr/npms/NewIndcUserR.np?indcMon=&indcSeq='+ numbers\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # BeautifulSoup를 사용하여 HTML 파싱\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    t = soup.find_all('h2', class_=\"newH2\")\n",
        "    title = t[0].get_text().strip()\n",
        "\n",
        "\n",
        "    # 원하는 요소를 선택합니다.\n",
        "    class1 = ['warning', 'watch', 'forecast']\n",
        "\n",
        "    # 클래스별로 크롤링한 값을 저장할 딕셔너리\n",
        "    alert_data = {key: [] for key in class1}\n",
        "\n",
        "\n",
        "    sql_update_prev_data = \"update tbDiseaseForecast set endDate = DATE_FORMAT(DATE_SUB(now(), INTERVAL 1 day), '%Y%m%d') where endDate = '99999999' and title <> %s\"\n",
        "    val_update_prev_data = (title, )\n",
        "    mycursor.execute(sql_update_prev_data, val_update_prev_data)\n",
        "\n",
        "    # 선택한 요소에서 데이터 추출\n",
        "    for class_name in class1:\n",
        "        alerts = soup.find_all('li', class_=class_name)  # <li> 태그 안의 해당 클래스명을 가진 요소를 선택\n",
        "        items = alert.find('ul').find_all('li')\n",
        "\n",
        "        for item in items:\n",
        "            dName = item.get_text().strip()\n",
        "            id = item.get(\"id\").split('_')[1]\n",
        "            dates = re.findall(date_pattern, title)\n",
        "            # Extracting start date and end date\n",
        "            start_date = dates[0]  # Removing dots from the date string\n",
        "            start_date = convertDate(start_date)\n",
        "            dType = 'W'\n",
        "            if (class_name == 'watch'):\n",
        "              dType = 'T'\n",
        "            elif (class_name == 'forecast'):\n",
        "              dType = 'F'\n",
        "\n",
        "            print(title)\n",
        "            print(dType)\n",
        "            print(dName)\n",
        "            print(id)\n",
        "            print(start_date)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Check if the title already exists in the database\n",
        "            sql_check_title = \"SELECT COUNT(*) FROM tbDiseaseForecast WHERE endDate = '99999999' and dName = %s\"\n",
        "            val_check_title = (dName,)\n",
        "\n",
        "            mycursor.execute(sql_check_title, val_check_title)\n",
        "            title_count = mycursor.fetchone()[0]\n",
        "\n",
        "            if title_count == 0:\n",
        "              # Define the SQL query to insert data into the table\n",
        "              sql = \"INSERT INTO tbDiseaseForecast (title, startDate, endDate, dType, dName) VALUES (%s, %s, '99999999', %s, %s)\"\n",
        "              val = (title, start_date, dType, dName)\n",
        "\n",
        "              # Execute the SQL query\n",
        "              mycursor.execute(sql, val)\n",
        "\n",
        "              # Commit changes to the database\n",
        "              mydb.commit()\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"해당 요소를 찾을 수 없습니다.\")"
      ],
      "metadata": {
        "id": "VBngYtmWsvq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H81mK6JMx_53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}